---
title: MIT6.1810实验（六）
seo_title: seo名称
toc: true
indent: true
top: false
comments: true
archive: true
cover: false
mathjax: false
pin: false
top_meta: false
bottom_meta: false
sidebar:
  - toc
tag:
  - 操作系统
  - MIT6.1810
categories: 项目实战
keywords: 文章关键词
updated: ''
img: /medias/featureimages/40.webp
date:
summary: 多线程
---
# MIT6.1810实验（六）
## MIT6.1810 Lab6
### 1.引言
#### 1.1实验要求
**①引言**
>**概述**：实现**用户进程切换**、使用**多线程加速程序**和**同步屏障**
{%list%}
做之前记得切换到对应分支git checkout thread
{%endlist%}
**②用户进程切换**
>**概述**：完善`user/uthread.c`和`user/uthread_switch.S`，实现线程的**创建和切换**功能
{%right%}
可以参考内核线程切换代码
{%endright%}
**③多线程加速**
>**概述**：`notxv6/ph.c`中实现了一个**仅能运行在单线程**下的哈希表，将其修改为**多线程下可行**并实现**加速**
{%list%}
该程序先通过put()向哈希表中加入大量的key，随后使用get()将其取出，多线程情况下会出现key的丢失
{%endlist%}
>在**主目录**下运行`make ph`，并传入**线程数量**为参数，如`./ph 1`表示**单线程**
{%right%}
出现key的丢失主要是没有加锁导致
{%endright%}
{%warning%}
注意本部分实验并不是在Xv6系统下完成，而是在多核心处理器的Linux/macOS电脑中完成
{%endwarning%}
>需要使用UNIX下的`pthread`**库函数**，本次实验需要使用的**相关函数**如下
```c
zfk@zfk-Legion-Y9000P-IRX8:~/xv6-labs-2023$ ./ph 1
100000 puts, 3.202 seconds, 31233 puts/second
0: 0 keys missing
100000 gets, 3.201 seconds, 31241 gets/second
zfk@zfk-Legion-Y9000P-IRX8:~/xv6-labs-2023$ ./ph 2
100000 puts, 1.757 seconds, 56908 puts/second
1: 16054 keys missing
0: 16054 keys missing
200000 gets, 3.565 seconds, 56106 gets/second
```
```c
pthread_mutex_t lock;            // declare a lock
pthread_mutex_init(&lock, NULL); // initialize the lock
pthread_mutex_lock(&lock);       // acquire lock
pthread_mutex_unlock(&lock);     // release lock
```
**④同步屏障**
>**概述**：完善`notxv6/barrier.c`下的`barrier()`函数，使得每个线程都在`barrier()`位置阻塞
{%list%}
同步屏障即程序的一个位置，所有参与的线程都需要等待直到所有其他线程都到达这个位置
{%endlist%}
{%warning%}
注意本部分实验并不是在Xv6系统下完成，而是在多核心处理器的Linux/macOS电脑中完成
{%endwarning%}
>需要使用UNIX下的`pthread`**库函数**，本次实验需要使用的**相关函数**如下，类似于`wake`和`sleep`
```c
// go to sleep on cond, releasing lock mutex, acquiring upon wake up
pthread_cond_wait(&cond, &mutex);
// wake up every thread sleeping on cond
pthread_cond_broadcast(&cond);     
```
**⑤实验结果**
>**测试准备**：**主目录**添加`time.txt`和`answers-thread.txt`，随后`make qemu`，退出`make grade`即可
{%list%}
两个txt前者填写花费的时间数，后者填写简答题的答案
{%endlist%}
![测试结果](/image/MIT.6.1810_Lab6.png)
#### 1.2Xv6线程
**①引言**
>**线程**：单个**串行执行代码**的单元，每个线程都有自己的**一套寄存器**和**程序栈**
{%list%}
不同于Linux，Xv6的一个进程只包含一个用户态线程和内核态线程
{%endlist%}
{%right%}
当进程执行系统调用/相应中断陷入内核，其用户线程状态会被保存，并激活其内核线程，最后再返回用户态
{%endright%}
>**定时器**：定时产生**中断**，从而强行将**CPU的控制权**从**用户态**转移给**内核态**

>**调度器线程**：每个`CPU`都有的一种**内核线程**，用于**线程切换**
{%list%}
调度器线程没有对应的进程和proc结构体，其信息如context都保存在对应的cpu结构体中
{%endlist%}
**②线程切换**
>**陷入内核**：**进程1**因为**定时器中断/系统调用**陷入内核，将**寄存器**保存在`trapframe`结构中，并执行**中断代码**

>**`yield()`**：由于**定时器中断**或**I/O阻塞**等原因，**内核线程1**调用`yield()`转让CPU
{%list%}
yield()将当前进程状态修改为RUNNABLE，并调用sched()
{%endlist%}
{%warning%}
注意这里需要使用锁，防止sched函数未调用完，其他CPU将RUNNABLE状态的进程1投入运行
{%endwarning%}
```c
  // give up the CPU if this is a timer interrupt.
  if(which_dev == 2)
    yield();
```
```c
// Give up the CPU for one scheduling round.
void
yield(void)
{
  struct proc *p = myproc();
  acquire(&p->lock);
  p->state = RUNNABLE;
  sched();
  release(&p->lock);
}
```
>`sched()`：做一些**合理性检查**，并跳转到`swtch`函数
```c
// Switch to scheduler.  Must hold only p->lock
// and have changed proc->state. Saves and restores
// intena because intena is a property of this
// kernel thread, not this CPU. It should
// be proc->intena and proc->noff, but that would
// break in the few places where a lock is held but
// there's no process.
void
sched(void)
{
  int intena;
  struct proc *p = myproc();

  if(!holding(&p->lock))
    panic("sched p->lock");
  if(mycpu()->noff != 1)
    panic("sched locks");
  if(p->state == RUNNING)
    panic("sched running");
  if(intr_get())
    panic("sched interruptible");

  intena = mycpu()->intena;
  swtch(&p->context, &mycpu()->context);
  mycpu()->intena = intena;
}
```
>`swtch.s`：将**内核线程1的寄存器**保存到其`context`结构中，随后加载**调度器线程**的`context`
{%list%}
Xv6会将第一个/第二个函数参数保存到a0/a1中，所以a0为&p->context，a1为&mycpu()->context
{%endlist%}
>加载了**调度器线程**的`context`之后，实际上就已经位于**调度器线程**中了
{%right%}
RA寄存器保存了当前函数的返回地址，ret指令会将PC寄存器设置为RA寄存器的值
{%endright%}
>**调度器线程**的`RA`寄存器保存的是`scheduler`函数**调用`swtch`函数处**
{%warning%}
该函数是从C代码调用的，Caller Saved Register被编译器保存在栈中，这里只需要保存Callee Saved Register
{%endwarning%}
```nasm
# Context switch
#
#   void swtch(struct context *old, struct context *new);
# 
# Save current registers in old. Load from new.	


.globl swtch
swtch:
        sd ra, 0(a0)
        sd sp, 8(a0)
        sd s0, 16(a0)
        sd s1, 24(a0)
        sd s2, 32(a0)
        sd s3, 40(a0)
        sd s4, 48(a0)
        sd s5, 56(a0)
        sd s6, 64(a0)
        sd s7, 72(a0)
        sd s8, 80(a0)
        sd s9, 88(a0)
        sd s10, 96(a0)
        sd s11, 104(a0)

        ld ra, 0(a1)
        ld sp, 8(a1)
        ld s0, 16(a1)
        ld s1, 24(a1)
        ld s2, 32(a1)
        ld s3, 40(a1)
        ld s4, 48(a1)
        ld s5, 56(a1)
        ld s6, 64(a1)
        ld s7, 72(a1)
        ld s8, 80(a1)
        ld s9, 88(a1)
        ld s10, 96(a1)
        ld s11, 104(a1)
        
        ret
```
>`scheduler()`：抹去**进程1**的记录，并释放在`yield`函数获取的**进程1的锁**，并**切换进程**，调用`swtch`函数
{%list%}
对进程1上锁，可以确保出让CPU操作的原子性，并防止中断干扰该操作，出让完CPU即可释放该锁
{%endlist%}
{%right%}
在scheduler()调用的swtch函数执行后，即切换到进程2的内核线程，最后层层返回到进程2的用户线程
{%endright%}
{%warning%}
注意是从swtch调用处开始执行的
{%endwarning%}
```c
// Per-CPU process scheduler.
// Each CPU calls scheduler() after setting itself up.
// Scheduler never returns.  It loops, doing:
//  - choose a process to run.
//  - swtch to start running that process.
//  - eventually that process transfers control
//    via swtch back to the scheduler.
void
scheduler(void)
{
  struct proc *p;
  struct cpu *c = mycpu();

  c->proc = 0;
  for(;;){
    // The most recent process to run may have had interrupts
    // turned off; enable them to avoid a deadlock if all
    // processes are waiting.
    intr_on();

    for(p = proc; p < &proc[NPROC]; p++) {
      acquire(&p->lock);
      if(p->state == RUNNABLE) {
        // Switch to chosen process.  It is the process's job
        // to release its lock and then reacquire it
        // before jumping back to us.
        p->state = RUNNING;
        c->proc = p;
        swtch(&c->context, &p->context);

        // Process is done running for now.
        // It should have changed its p->state before coming back.
        c->proc = 0;
      }
      release(&p->lock);
    }
  }
}

```
### 2.具体实现
#### 2.1用户进程切换
**①定义上下文结构体**
>**概述**：参考**内核线程**的切换，需要将**部分寄存器**保存在结构体`context`中
{%list%}
可以参考kernel/proc.h中context结构，并在user/uthread.c中添加如下代码
{%endlist%}
```c
struct thread_context {
  uint64 ra;
  uint64 sp;

  // callee-saved
  uint64 s0;
  uint64 s1;
  uint64 s2;
  uint64 s3;
  uint64 s4;
  uint64 s5;
  uint64 s6;
  uint64 s7;
  uint64 s8;
  uint64 s9;
  uint64 s10;
  uint64 s11;
};
struct thread {
  char       stack[STACK_SIZE]; /* the thread's stack */
  int        state;             /* FREE, RUNNING, RUNNABLE */
  struct thread_context t_context; //保存线程上下文
};
```
**②`thread_create`**
>**概述**：从线程运行队列`all_thread`中找到**空闲位置**，并修改一些**关键状态**
{%list%}
主要是设置线程的状态和context，其中context只需要设置ra和sp，因为其他寄存器刚创建时无意义
{%endlist%}
>`ra`为**返回地址**，设置为**要运行的函数**`func`，`sp`为**栈指针**，设置为**栈底部**`stack+STACK_SIZE`
{%right%}
可以参考kernel/proc.c中allocproc()
{%endright%}
```c
void 
thread_create(void (*func)())
{
  struct thread *t;

  for (t = all_thread; t < all_thread + MAX_THREAD; t++) {
    if (t->state == FREE) break;
  }
  t->state = RUNNABLE;
  // YOUR CODE HERE
  t->t_context.ra = (uint64)func;
  t->t_context.sp = (uint64)&t->stack + STACK_SIZE;
}
```
```c
// Look in the process table for an UNUSED proc.
// If found, initialize state required to run in the kernel,
// and return with p->lock held.
// If there are no free procs, or a memory allocation fails, return 0.
static struct proc*
allocproc(void)
{
  struct proc *p;

  for(p = proc; p < &proc[NPROC]; p++) {
    acquire(&p->lock);
    if(p->state == UNUSED) {
      goto found;
    } else {
      release(&p->lock);
    }
  }
  return 0;

found:
  p->pid = allocpid();
  p->state = USED;

  // Allocate a trapframe page.
  if((p->trapframe = (struct trapframe *)kalloc()) == 0){
    freeproc(p);
    release(&p->lock);
    return 0;
  }

  // An empty user page table.
  p->pagetable = proc_pagetable(p);
  if(p->pagetable == 0){
    freeproc(p);
    release(&p->lock);
    return 0;
  }

  // Set up new context to start executing at forkret,
  // which returns to user space.
  memset(&p->context, 0, sizeof(p->context));
  p->context.ra = (uint64)forkret;
  p->context.sp = p->kstack + PGSIZE;

  return p;
}
```
**③`thread_switch`**
>**概述**：切换**线程的上下文**，并完善`thread_schedule()`
{%right%}
可以参考内核线程切换代码kernel/swtch.S
{%endright%}
```c
	.text

	/*
         * save the old thread's registers,
         * restore the new thread's registers.
         */

	.globl thread_switch
thread_switch:
	/* YOUR CODE HERE */
	  sd ra, 0(a0)
    sd sp, 8(a0)
    sd s0, 16(a0)
    sd s1, 24(a0)
    sd s2, 32(a0)
    sd s3, 40(a0)
    sd s4, 48(a0)
    sd s5, 56(a0)
    sd s6, 64(a0)
    sd s7, 72(a0)
    sd s8, 80(a0)
    sd s9, 88(a0)
    sd s10, 96(a0)
    sd s11, 104(a0)

    ld ra, 0(a1)
    ld sp, 8(a1)
    ld s0, 16(a1)
    ld s1, 24(a1)
    ld s2, 32(a1)
    ld s3, 40(a1)
    ld s4, 48(a1)
    ld s5, 56(a1)
    ld s6, 64(a1)
    ld s7, 72(a1)
    ld s8, 80(a1)
    ld s9, 88(a1)
    ld s10, 96(a1)
    ld s11, 104(a1)
	ret    /* return to ra */
```
```c
void 
thread_schedule(void)
{
  struct thread *t, *next_thread;

  /* Find another runnable thread. */
  next_thread = 0;
  t = current_thread + 1;
  for(int i = 0; i < MAX_THREAD; i++){
    if(t >= all_thread + MAX_THREAD)
      t = all_thread;
    if(t->state == RUNNABLE) {
      next_thread = t;
      break;
    }
    t = t + 1;
  }

  if (next_thread == 0) {
    printf("thread_schedule: no runnable threads\n");
    exit(-1);
  }

  if (current_thread != next_thread) {         /* switch threads?  */
    next_thread->state = RUNNING;
    t = current_thread;
    current_thread = next_thread;
    /* YOUR CODE HERE
     * Invoke thread_switch to switch from t to next_thread:
     * thread_switch(??, ??);
     */
    thread_switch((uint64)&t->t_context, (uint64)&next_thread->t_context);
  } else
    next_thread = 0;
}
```
#### 2.2多线程加速
**①代码详解**
>**哈希表结构**：本质上为一**链表数组**，数组长度为`5`
```c
#define NBUCKET 5
#define NKEYS 100000

struct entry {
  int key;
  int value;
  struct entry *next;
};
struct entry *table[NBUCKET];
```
>**插入**：`put()`先根据`key`找到哈希表**对应链表并遍历**，若有对应`key`，则修改其`value`，否则**插入节点**
{%list%}
使用头插法插入，将新节点的next指针修改为原来的数组元素，并将数组元素重置为新节点指针
{%endlist%}
{%warning%}
当进程1刚设置完*p = e1，进程2就设置*p = e2，则e1会丢失，因为此时两者的p是一致的
{%endwarning%}
```c
static void 
insert(int key, int value, struct entry **p, struct entry *n)
{
  struct entry *e = malloc(sizeof(struct entry));
  e->key = key;
  e->value = value;
  e->next = n;
  *p = e;
}

static 
void put(int key, int value)
{
  int i = key % NBUCKET;

  // is the key already present?
  struct entry *e = 0;
  for (e = table[i]; e != 0; e = e->next) {
    if (e->key == key)
      break;
  }
  if(e){
    // update the existing key.
    e->value = value;
  } else {
    // the new is new.
    insert(key, value, &table[i], table[i]);
  }
}
```
>**取出**：根据`key`找到哈希表**对应链表并遍历**
{%list%}
取出操作不涉及多线程，且和插入操作相隔开，所以不需要枷锁
{%endlist%}
```c
static struct entry*
get(int key)
{
  int i = key % NBUCKET;


  struct entry *e = 0;
  for (e = table[i]; e != 0; e = e->next) {
    if (e->key == key) break;
  }

  return e;
}
```
**②加锁**
>**概述**：声明**全局的锁**，并在`main`函数中**初始化**，并给`put`函数**上锁**
{%list%}
put函数每次只涉及一个桶，所以给每个桶上锁，如果给整个哈希表上锁，会限制性能
{%endlist%}
```c
pthread_mutex_t locks[NBUCKET];
```
```c
int
main(int argc, char *argv[])
{
  pthread_t *tha;
  void *value;
  double t1, t0;


  if (argc < 2) {
    fprintf(stderr, "Usage: %s nthreads\n", argv[0]);
    exit(-1);
  }
  //初始化声明的锁
  for (int i = 0; i < NBUCKET; i++) {
    pthread_mutex_init(&locks[i], NULL);
  }
  nthread = atoi(argv[1]);
  tha = malloc(sizeof(pthread_t) * nthread);
  srandom(0);
  assert(NKEYS % nthread == 0);
  for (int i = 0; i < NKEYS; i++) {
    keys[i] = random();
  }

  //
  // first the puts
  //
  t0 = now();
  for(int i = 0; i < nthread; i++) {
    assert(pthread_create(&tha[i], NULL, put_thread, (void *) (long) i) == 0);
  }
  for(int i = 0; i < nthread; i++) {
    assert(pthread_join(tha[i], &value) == 0);
  }
  t1 = now();

  printf("%d puts, %.3f seconds, %.0f puts/second\n",
         NKEYS, t1 - t0, NKEYS / (t1 - t0));

  //
  // now the gets
  //
  t0 = now();
  for(int i = 0; i < nthread; i++) {
    assert(pthread_create(&tha[i], NULL, get_thread, (void *) (long) i) == 0);
  }
  for(int i = 0; i < nthread; i++) {
    assert(pthread_join(tha[i], &value) == 0);
  }
  t1 = now();

  printf("%d gets, %.3f seconds, %.0f gets/second\n",
         NKEYS*nthread, t1 - t0, (NKEYS*nthread) / (t1 - t0));
}
```
```c
static 
void put(int key, int value)
{
  int i = key % NBUCKET;
  //给对应的桶加锁
  pthread_mutex_lock(&locks[i]);

  // is the key already present?
  struct entry *e = 0;
  for (e = table[i]; e != 0; e = e->next) {
    if (e->key == key)
      break;
  }
  if(e){
    // update the existing key.
    e->value = value;
  } else {
    // the new is new.
    insert(key, value, &table[i], table[i]);
  }
  //给对应的桶解锁
  pthread_mutex_unlock(&locks[i]);

}
```
#### 2.3内存屏障
**①代码详解**
>**`barrier`**：结构如下，其中`nthread`表示**参与的进程数**，`round`表示**轮数**
{%list%}
pthread_mutex_t和pthread_cond_t为互斥锁和条件变量，配合使用以保护共享数据
{%endlist%}
{%right%}
条件变量会第一时间通知线程可以获取锁
{%endright%}
```c
struct barrier {
  pthread_mutex_t barrier_mutex;
  pthread_cond_t barrier_cond;
  int nthread;      // Number of threads that have reached this round of the barrier
  int round;     // Barrier round
} bstate;
```
>**`main()`**：首先创建**多个线程**，每个线程运行`thread`函数，最后通过`pthread_join`检验线程**是否提前结束**
{%list%}
如果传递给 pthread_join函数的线程标识符是无效的或者已经结束的线程，则会返回失败
{%endlist%}
```c
int
main(int argc, char *argv[])
{
  pthread_t *tha;
  void *value;
  long i;
  double t1, t0;

  if (argc < 2) {
    fprintf(stderr, "%s: %s nthread\n", argv[0], argv[0]);
    exit(-1);
  }
  nthread = atoi(argv[1]);
  tha = malloc(sizeof(pthread_t) * nthread);
  srandom(0);

  barrier_init();

  for(i = 0; i < nthread; i++) {
    assert(pthread_create(&tha[i], NULL, thread, (void *) i) == 0);
  }
  for(i = 0; i < nthread; i++) {
    assert(pthread_join(tha[i], &value) == 0);
  }
  printf("OK; passed\n");
}
```
>**`thread`**：执行一个循环，**每次循环**调用`barrier()`，随后**睡眠随机秒数**
{%list%}
只有当barrier起到内存屏障的作用，t即round才会和i相等
{%endlist%}
```c
static void *
thread(void *xa)
{
  long n = (long) xa;
  long delay;
  int i;

  for (i = 0; i < 20000; i++) {
    int t = bstate.round;
    assert (i == t);
    barrier();
    usleep(random() % 100);
  }

  return 0;
}
```
**②`barrier`**
>**概述**：当**全部线程**到达内存屏障时，屏障的`nthread`**重置**，`round`**加一**，反之`nthread`**加一并睡眠**
```c
static void 
barrier()
{
  // YOUR CODE HERE
  //
  // Block until all threads have called barrier() and
  // then increment bstate.round.
  //
  //获取互斥锁，以保护共享变量
  pthread_mutex_lock(&bstate.barrier_mutex);
  //如果不是所有线程都到达屏障
  //释放互斥锁并进入睡眠状态，等待信号量将其唤醒
  if(++bstate.nthread < nthread){
    pthread_cond_wait(&bstate.barrier_cond, &bstate.barrier_mutex);
  }else{
    //重置屏障
    bstate.nthread = 0;
    bstate.round++;
    //唤醒等待信号量的所有线程
    pthread_cond_broadcast(&bstate.barrier_cond);
  }
  //释放互斥锁
  pthread_mutex_unlock(&bstate.barrier_mutex);
}
```
